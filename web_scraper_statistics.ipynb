{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote\n",
        "from urllib.parse import urlparse, unquote\n",
        "import re\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark==3.3.2\n",
        "!pip install beautifulsoup4 requests\n",
        "\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, regexp_replace, format_number\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"HeroData\").getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumRows\", 10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17D5hoBlzsjc",
        "outputId": "b485224b-903d-4d34-d1ed-0e372e3e0553"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.3.2 in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.3.2) (0.10.9.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL for the Dota 2 heroes list on Gamepedia\n",
        "url = \"https://dota2.gamepedia.com/Heroes\"\n",
        "\n",
        "# Fetch the HTML content from the URL\n",
        "response = requests.get(url)\n",
        "html_content = response.content\n",
        "\n",
        "# Parse the HTML using BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "# Find all hero names within <span> elements with the specified style\n",
        "hero_spans = soup.find_all(\"span\", style=\"font-size:17px; color:white; text-shadow:-1px 0 0.2em black, 0 1px 0.2em black, 1px 0 0.2em black, 0 -1px 0.2em black;\")\n",
        "\n",
        "# Extract hero names and store them in a list\n",
        "hero_names = [span.text.strip() for span in hero_spans]\n",
        "\n",
        "all_hero_names = [\n",
        "    \"https://dota2protracker.com/hero/\" + quote(name) + \"/new\" for name in hero_names\n",
        "]\n"
      ],
      "metadata": {
        "id": "IRDWE0CW6_sf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_modes = {\n",
        "    'pos1': \"pos 1,carry,core\",\n",
        "    'pos2': \"pos 2,mid,core\",\n",
        "    'pos3': \"pos 3,offlane,core\",\n",
        "    'pos4': \"pos 4, support\",\n",
        "    'pos5': \"pos 5, support\"\n",
        "}\n",
        "\n",
        "roles = [\n",
        "    \"th-pos-1\",\n",
        "    \"th-pos-2\",\n",
        "    \"th-pos-3\",\n",
        "    \"th-pos-4\",\n",
        "    \"th-pos-5\"\n",
        "]\n",
        "\n",
        "def get_role_by_input_parameter(input_parameter):\n",
        "    try:\n",
        "        role = roles[input_parameter - 1]\n",
        "        return role\n",
        "    except IndexError:\n",
        "        return \"Invalid input_parameter. Please choose a valid role.\"\n",
        "\n",
        "# def get_analysis_mode(position):\n",
        "#   if position is not None:\n",
        "#       print(position)\n",
        "#   else:\n",
        "#       print(f\"Invalid analysis_mode: {analysis_mode}\")"
      ],
      "metadata": {
        "id": "cgC8evAN9-6B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_heroes_to_draft(input_heroes, analysis_mode):\n",
        "\n",
        "  position = analysis_modes.get(analysis_mode)\n",
        "\n",
        "  print(\"Correlating input heroes with their pages...\")\n",
        "  # List of hero URLs from dota2protracker\n",
        "  hero_list = []\n",
        "  hero_list_index = []\n",
        "\n",
        "  # Iterate through the input hero names\n",
        "  for index, input_hero in enumerate(input_heroes):\n",
        "      # Convert the input hero name to a standardized format for comparison\n",
        "      standardized_input_hero = input_hero[0].lower().replace(\" \", \"%20\")\n",
        "\n",
        "      # Find matches in all_hero_names and store the index of the match\n",
        "      matches = [(i, link) for i, link in enumerate(all_hero_names) if standardized_input_hero in link.lower()]\n",
        "\n",
        "      # Append matches to the hero_list list and store the indices in hero_list_index\n",
        "      for match_index, match_link in matches:\n",
        "          hero_list.append(match_link)\n",
        "          hero_list_index.append(match_index)\n",
        "\n",
        "  # Check if the lengths of input_heroes and all_hero_names are equal\n",
        "  if len(input_heroes) != len(hero_list):\n",
        "      print(hero_list)\n",
        "      assert len(input_heroes) == len(hero_list), \"Lengths of input_heroes and all_hero_names are not equal.\"\n",
        "\n",
        "  display_cleaned_hero_list = [unquote(urlparse(hero).path.split('/')[-2]).replace('%20', '_').replace('%27', '').replace('#', '').replace(' ', '_').replace('-', '_').replace(\"'\", '').upper() for hero in hero_list]\n",
        "\n",
        "\n",
        "  #WebScrap data and generate pyspark dataframe\n",
        "  print(\"Web scraping data into pyspark dataframe...\")\n",
        "  for index, url in enumerate(hero_list):\n",
        "\n",
        "    # Fetch the HTML content from the URL\n",
        "    response = requests.get(url)\n",
        "    html_content = response.content\n",
        "\n",
        "    # Parse the HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    heroes_data = []\n",
        "\n",
        "    # Find the div with the corresponding id role and class \"top-heroes-box\"\n",
        "    hero_rows = soup.find(id = get_role_by_input_parameter(input_heroes[index][1]), class_=\"top-heroes-box\")\n",
        "\n",
        "    # Find all divs with the specified class within the previously found div\n",
        "    hero_rows_filtered = hero_rows.find_all(class_=\"flex py-1 px-2 bg-d2pt-gray-3 justify-start border-solid border-b border-d2pt-gray-5\")\n",
        "\n",
        "    # Iterate through each found div\n",
        "    for row in hero_rows_filtered:\n",
        "        # Extract the values of data-hero, data-wr, and data-pos attributes\n",
        "        data_hero = row.get('data-hero')\n",
        "        data_wr = row.get('data-wr')\n",
        "        data_pos = row.get('data-pos')\n",
        "        data_matches = row.get('data-matches')\n",
        "\n",
        "        #Filtering by number of matches and corresponding role you want to play\n",
        "        if int(data_matches) > 15 and data_pos == position:\n",
        "            heroes_data.append({'data_hero': data_hero, 'data_wr': data_wr})\n",
        "\n",
        "    df = spark.createDataFrame(heroes_data)\n",
        "\n",
        "    df = df.withColumn(\"data_wr\", (regexp_replace(col(\"data_wr\"), \"%\", \"\").cast(FloatType()) / 100))\n",
        "    df = df.withColumn(\"data_wr\", format_number(col(\"data_wr\"), 3))\n",
        "\n",
        "    df.createOrReplaceTempView(f\"hero_{index}\")\n",
        "\n",
        "  print(\"Generating SQL query...\")\n",
        "  # Generate the SQL query for creating the selected_heroes view\n",
        "  union_queries = \"\\n    UNION\\n    \".join([\n",
        "      f\"(SELECT data_hero FROM hero_{i})\" # Add WHERE data_wr < .5 ORDER BY data_wr ASC if you want the old version\n",
        "      for i in range(len(display_cleaned_hero_list))\n",
        "  ])\n",
        "\n",
        "  # Generate the main SQL query\n",
        "  select_queries = \",\\n    \".join([\n",
        "      f\"b{i}.data_wr AS {data_hero}\"\n",
        "      for i, data_hero in enumerate(display_cleaned_hero_list)\n",
        "  ])\n",
        "\n",
        "  aggregate_queries = \" + \".join([\n",
        "      f\"b{i}.data_wr\"\n",
        "      for i in range(len(display_cleaned_hero_list))\n",
        "  ])\n",
        "\n",
        "  left_join_queries = \"\\n  \".join([\n",
        "      f\"LEFT JOIN hero_{i} b{i} ON a.data_hero = b{i}.data_hero\"\n",
        "      for i in range(len(display_cleaned_hero_list))\n",
        "  ])\n",
        "\n",
        "  where_conditions = \"\\n    AND \".join([\n",
        "      f\"b{i}.data_wr IS NOT NULL\"\n",
        "      for i in range(len(display_cleaned_hero_list))\n",
        "  ])\n",
        "\n",
        "  sql_query = f'''\n",
        "    SELECT *\n",
        "    FROM (\n",
        "      SELECT\n",
        "        UPPER(a.data_hero)                                                 AS POTENTIAL_HERO,\n",
        "        ROUND(({aggregate_queries}) / {len(display_cleaned_hero_list)}, 3) AS LOSS_PROBABILITY_SCORE,\n",
        "        {select_queries}\n",
        "      FROM (\n",
        "        {union_queries}\n",
        "      ) a\n",
        "      {left_join_queries}\n",
        "      WHERE {where_conditions}\n",
        "      ORDER BY LOSS_PROBABILITY_SCORE ASC\n",
        "    )\n",
        "    WHERE 1=1\n",
        "      AND LOSS_PROBABILITY_SCORE < 0.5\n",
        "  '''\n",
        "\n",
        "  # Execute the SQL query\n",
        "  spark.sql(sql_query).show()"
      ],
      "metadata": {
        "id": "u-614zT91KwZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input hero names\n",
        "input_heroes = [\n",
        "                [\"PUCK\", 2],\n",
        "                [\"GRIMSTROKE\", 4],\n",
        "                [\"SPECTRE\", 1],\n",
        "                [\"CENTAUR\", 3],\n",
        "                # [\"PHOENIX\", 5]\n",
        "               ]\n",
        "\n",
        "# Available Analysys mode options: \"pos1\", \"pos2\", \"pos3\", \"pos4\", \"pos5\"\n",
        "best_heroes_to_draft(input_heroes, analysis_mode = 'pos3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KBW_PfgUNbK",
        "outputId": "435962b9-6592-4829-e2ce-b952dfaf3e03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlating input heroes with their pages...\n",
            "Web scraping data into pyspark dataframe...\n",
            "Generating SQL query...\n",
            "+--------------+----------------------+-----+----------+-------+-----------------+\n",
            "|POTENTIAL_HERO|LOSS_PROBABILITY_SCORE| PUCK|GRIMSTROKE|SPECTRE|CENTAUR_WARRUNNER|\n",
            "+--------------+----------------------+-----+----------+-------+-----------------+\n",
            "|        VISAGE|                 0.409|0.500|     0.343|  0.392|            0.400|\n",
            "|         VIPER|                 0.433|0.480|     0.424|  0.386|            0.441|\n",
            "|     PANGOLIER|                 0.448|0.368|     0.520|  0.405|            0.500|\n",
            "| NIGHT STALKER|                  0.45|0.373|     0.451|  0.512|            0.463|\n",
            "|        KUNKKA|                 0.456|0.429|     0.441|  0.493|            0.460|\n",
            "|         LYCAN|                 0.462|0.375|     0.419|  0.400|            0.652|\n",
            "|   EARTHSHAKER|                 0.471|0.433|     0.472|  0.569|            0.409|\n",
            "|         MARCI|                 0.474|0.432|     0.509|  0.478|            0.477|\n",
            "|  CHAOS KNIGHT|                 0.483|0.468|     0.490|  0.492|            0.483|\n",
            "|     SAND KING|                 0.484|0.455|     0.417|  0.597|            0.467|\n",
            "|    OMNIKNIGHT|                 0.486|0.400|     0.565|  0.500|            0.481|\n",
            "|   BEASTMASTER|                 0.493|0.469|     0.465|  0.450|            0.590|\n",
            "|       SLARDAR|                 0.494|0.517|     0.537|  0.441|            0.482|\n",
            "+--------------+----------------------+-----+----------+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XHrISAnPROhz"
      }
    }
  ]
}